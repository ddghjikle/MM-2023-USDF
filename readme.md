# Uncertainty-Aware Variate Decomposition for Self-supervised Blind Image Deblurring (ACM MM 2023)
Official implementation of ["**[Uncertainty-Aware Variate Decomposition for Self-supervised Blind Image Deblurring (ACM MM 2023)](https://doi.org/10.1145/3581783.3612535)**"], **[Runhua Jiang](https://scholar.google.com.hk/citations?hl=zh-CN&view_op=list_works&gmla=AOV7GLOtVSSA5YAZIfaFwu9aInPr2OI4l-brSoherrpowMD_NndZ-hEbqmPezX6qy8zAq-KrcP1em6MjegzbUfzLK7U&user=mD3lO60AAAAJ)**, **[YaHong Han](http://cic.tju.edu.cn/faculty/hanyahong/index.html)**.
DOI: https://doi.org/10.1145/3581783.3612535

> **Abstract:** *Blind image deblurring remains challenging due to the ill-posed nature of the traditional blurring function. Although previous supervised methods have achieved great breakthrough with synthetic blurry-sharp image pairs, their generalization ability to real-world blurs is limited by the discrepancy between synthetic and real blurs. To overcome this limitation, unsupervised deblurring methods have been proposed by using natural priors or generative adversarial networks. However, natural priors are vulnerable to random blur artifacts, while generators of generative adversarial networks always produce inaccurate details and unrealistic colors. Consequently, previous methods easily suffer from slow convergence and poor performance. In this work, we propose to formulate the traditional blurring function as the composition of multiple variates, thus allowing us explicitly define characteristics of residual images between blurry and sharp images. We also propose a multi-step self-supervised deblurring framework to address the slow convergence issue. Our framework continuously decomposes and composes input images, thus utilizing the uncertainty of blur artifacts to obtain diverse pseudo blurry-sharp image pairs for self-supervised learning. This framework is more efficient than previous methods, as it does not rely on natural priors or GANs. Extensive comparisons demonstrate that the proposed framework outperforms state-of-the-art unsupervised methods on both dynamic scene, human-aware centric motion, real-world and out-of-focus deblurring datasets.*

### The codes will be released once they are annotated.

## 1. Different framework of unsupervised deblurring

<p align="center">
    <img src='/Introduction.png' width=700/>
</p>

**(a) Prior-based Methods:**

- Pre-defined Kernels
- Inaccurate Priors

**(b) CycleGAN-based Methods:**

- Expensive computation and unreliable training of GAN
- Multi-branch for deblurring or blurring

**(c) Ours:**

- Decomposition and randomly composition to obtain unsupervised/self-supervised learning
- Architecture-agnostic and lightweight framework that can support both CNN and ViT

<p align="center">
    <img src='/final.png' width=400/>
</p>

## 2. Method

<p align="center">
    <img src='/Framework.png' width=800/>
</p>
**(a) Left:**

- The proposed self-supervised deblurring framework. A neural network $f$ is taken to disengle blurry inputs $I_b$ as sharp images, content-dependent artifacts and content-independent noises. By random composition and decomposition, $f$ is optimized with diverse pseudo sharp-blurry image pairs.

**(b) Middle:**

- Architecture of $f$. It consists of a deblurring subnetwork (top row) and  a estimation subnetwork (bottom row) 

**(c) Right:**

-  Uncertain combinations of results generated by $f$.

## 3. Usage
### 3.1 Prepare data
The datasets used in the paper are available at the following links:
* [GoPro](https://seungjunnah.github.io/Datasets/gopro.html)
* [HIDE](https://github.com/joanshen0508/HA_deblur)
* [RealBlur](https://github.com/rimchang/RealBlur)


### 3.2 Dependencies

* Python 3.6.15
* PyTorch 1.9.0
* numpy
* Pillow
* torchvision
* scipy

### 3.3 Train

```
python train.py --device 0 --config config_gopro.json --tag GoPro
```

### Citation
If you find our code or paper useful, please consider citing:
```
@inproceedings{jiang2023uncertainty,
  title={Uncertainty-Aware Variate Decomposition for Self-supervised Blind Image Deblurring},
  author={Runhua Jiang and Yahong Han},
  booktitle={Proceedings of the 31st ACM International Conference on Multimedia},
  year={2023}
}
```

### Acknowledgments

The code borrows heavily from [CVF-SID](https://github.com/Reyhanehne/CVF-SID_PyTorch) and [Unsupervised-Domain-Specific-Deblurring](https://github.com/ustclby/Unsupervised-Domain-Specific-Deblurring). Thanks them very much for their sharing.
